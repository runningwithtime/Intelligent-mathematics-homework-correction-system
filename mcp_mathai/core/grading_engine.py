# ===============================
# core/grading_engine.py
# ===============================

import asyncio
import base64
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

from config.settings import settings
from utils.logger import setup_logger

logger = setup_logger("grading_engine")

class GradingEngine:
    """åŸæœ‰çš„æ‰¹æ”¹å¼•æ“æ¥å£ - ä¿æŒå…¼å®¹æ€§"""

    def __init__(self, mcp_client, model_selector):
        self.mcp_client = mcp_client
        self.model_selector = model_selector
        self.nvidia_api_key = settings.get_api_key()
        logger.info("åˆå§‹åŒ–æ‰¹æ”¹å¼•æ“")

    async def grade_homework(self, homework_id: int, image_path: str, grade_level: str) -> Dict[str, Any]:
        """æ‰¹æ”¹ä½œä¸š - å…¼å®¹æ¥å£"""
        logger.info(f"å¼€å§‹æ‰¹æ”¹ä½œä¸š: ID={homework_id}, å¹´çº§={grade_level}")

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨çœŸæ­£çš„AIæ‰¹æ”¹
        if await self._should_use_ai_grading():
            logger.info("ä½¿ç”¨AIæ‰¹æ”¹å¼•æ“")
            return await self._ai_grade_homework(homework_id, image_path, grade_level)
        else:
            logger.warning("AIæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ‰¹æ”¹æ¨¡å¼")
            return await self._basic_grade_homework(homework_id, image_path, grade_level)

    async def _should_use_ai_grading(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨AIæ‰¹æ”¹"""
        try:
            # æ£€æŸ¥MCPå®¢æˆ·ç«¯è¿æ¥
            if not self.mcp_client:
                return False

            # æ£€æŸ¥APIå¯†é’¥
            if not self.nvidia_api_key or self.nvidia_api_key == "nvapi-xxx":
                logger.warning("NVIDIA APIå¯†é’¥æœªé…ç½®")
                return False

            # å°è¯•ç®€å•çš„APIè°ƒç”¨æµ‹è¯•
            test_response = await self._test_nvidia_api()
            return test_response

        except Exception as e:
            logger.error(f"AIæœåŠ¡æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def _test_nvidia_api(self) -> bool:
        """æµ‹è¯•NVIDIA APIè¿æ¥"""
        try:
            # ç®€å•çš„æµ‹è¯•è¯·æ±‚
            test_data = {
                "model": settings.get("models.nvidia.model"),
                "messages": [{"role": "user", "content": "æµ‹è¯•è¿æ¥"}],
                "max_tokens": 10
            }

            # é€šè¿‡MCPå®¢æˆ·ç«¯æµ‹è¯•
            response = await self.mcp_client.call_tool("nvidia_chat", test_data)
            logger.info("NVIDIA APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            return True

        except Exception as e:
            logger.warning(f"NVIDIA APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def _ai_grade_homework(self, homework_id: int, image_path: str, grade_level: str) -> Dict[str, Any]:
        """çœŸæ­£çš„AIæ‰¹æ”¹æµç¨‹"""
        start_time = datetime.now()
        logger.info("ğŸš€ å¼€å§‹AIæ‰¹æ”¹æµç¨‹")

        try:
            # æ­¥éª¤1: å›¾åƒé¢„å¤„ç†
            logger.info("ğŸ“¸ æ­¥éª¤1: å›¾åƒé¢„å¤„ç†")
            processed_image = await self._process_image(image_path)

            # æ­¥éª¤2: AIå›¾åƒè¯†åˆ«
            logger.info("ğŸ¤– æ­¥éª¤2: AIå›¾åƒè¯†åˆ«")
            ocr_results = await self._ai_image_recognition(processed_image, grade_level)

            # æ­¥éª¤3: AIé¢˜ç›®åˆ†æ
            logger.info("ğŸ“ æ­¥éª¤3: AIé¢˜ç›®åˆ†æ")
            analyzed_questions = await self._ai_analyze_questions(ocr_results, grade_level)

            # æ­¥éª¤4: AIæ‰¹æ”¹
            logger.info("âœï¸ æ­¥éª¤4: AIæ™ºèƒ½æ‰¹æ”¹")
            graded_questions = await self._ai_grade_questions(analyzed_questions, grade_level)

            # æ­¥éª¤5: ç”ŸæˆAIåé¦ˆ
            logger.info("ğŸ’¬ æ­¥éª¤5: ç”ŸæˆAIåé¦ˆ")
            ai_feedback = await self._generate_ai_feedback(graded_questions, grade_level)

            # æ­¥éª¤6: ç”Ÿæˆç»ƒä¹ é¢˜
            logger.info("ğŸ“š æ­¥éª¤6: ç”Ÿæˆç»ƒä¹ é¢˜")
            practice_problems = await self._generate_practice_problems(graded_questions, grade_level)

            # ç¼–è¯‘ç»“æœ
            processing_time = (datetime.now() - start_time).total_seconds()
            final_results = self._compile_ai_results(
                graded_questions, ai_feedback, practice_problems,
                processing_time, grade_level
            )

            logger.info(f"âœ… AIæ‰¹æ”¹å®Œæˆï¼Œç”¨æ—¶: {processing_time:.2f}ç§’")
            return final_results

        except Exception as e:
            logger.error(f"âŒ AIæ‰¹æ”¹å¤±è´¥: {e}")
            # å¦‚æœAIæ‰¹æ”¹å¤±è´¥ï¼Œé™çº§åˆ°åŸºç¡€æ¨¡å¼
            return await self._basic_grade_homework(homework_id, image_path, grade_level)

    async def _process_image(self, image_path: str) -> Dict[str, Any]:
        """å›¾åƒé¢„å¤„ç†"""
        try:
            with open(image_path, 'rb') as f:
                image_data = f.read()

            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(image_data).decode('utf-8')

            return {
                "path": image_path,
                "base64": image_base64,
                "size": len(image_data)
            }

        except Exception as e:
            logger.error(f"å›¾åƒå¤„ç†å¤±è´¥: {e}")
            raise

    async def _ai_image_recognition(self, processed_image: Dict[str, Any], grade_level: str) -> Dict[str, Any]:
        """AIå›¾åƒè¯†åˆ«"""
        try:
            prompt = f"""
            è¯·åˆ†æè¿™å¼ {grade_level}æ•°å­¦ä½œä¸šå›¾ç‰‡ï¼Œè¯†åˆ«å‡ºæ‰€æœ‰é¢˜ç›®å’Œå­¦ç”Ÿç­”æ¡ˆã€‚

            è¿”å›JSONæ ¼å¼ï¼š
            {{
                "questions": [
                    {{
                        "number": 1,
                        "question_text": "é¢˜ç›®å†…å®¹",
                        "student_answer": "å­¦ç”Ÿç­”æ¡ˆ",
                        "confidence": 0.95
                    }}
                ],
                "total_questions": é¢˜ç›®æ•°é‡
            }}
            """

            request_data = {
                "model": settings.get("models.nvidia.model"),
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{processed_image['base64']}"}
                            }
                        ]
                    }
                ],
                "max_tokens": 2000,
                "temperature": 0.1
            }

            response = await self.mcp_client.call_tool("nvidia_vision", request_data)

            # è§£æå“åº”
            if isinstance(response, str):
                try:
                    return json.loads(response)
                except:
                    return {"questions": [], "total_questions": 0, "error": "è§£æå¤±è´¥"}

            return response

        except Exception as e:
            logger.error(f"AIå›¾åƒè¯†åˆ«å¤±è´¥: {e}")
            raise

    async def _ai_analyze_questions(self, ocr_results: Dict[str, Any], grade_level: str) -> List[Dict[str, Any]]:
        """AIåˆ†æé¢˜ç›®"""
        try:
            questions = ocr_results.get("questions", [])
            analyzed = []

            for q in questions:
                prompt = f"""
                åˆ†æè¿™é“{grade_level}æ•°å­¦é¢˜ï¼š
                é¢˜ç›®ï¼š{q.get('question_text', '')}
                å­¦ç”Ÿç­”æ¡ˆï¼š{q.get('student_answer', '')}

                è¿”å›JSONï¼š
                {{
                    "question_type": "é¢˜ç›®ç±»å‹",
                    "topic": "çŸ¥è¯†ç‚¹",
                    "difficulty": "éš¾åº¦",
                    "correct_answer": "æ­£ç¡®ç­”æ¡ˆ",
                    "solution_steps": ["è§£é¢˜æ­¥éª¤"]
                }}
                """

                request_data = {
                    "model": settings.get("models.nvidia.model"),
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 1000,
                    "temperature": 0.1
                }

                analysis = await self.mcp_client.call_tool("nvidia_chat", request_data)

                if isinstance(analysis, str):
                    try:
                        analysis = json.loads(analysis)
                    except:
                        analysis = {"question_type": "è®¡ç®—é¢˜", "topic": "æœªçŸ¥", "difficulty": "ä¸­ç­‰"}

                # åˆå¹¶æ•°æ®
                analyzed_q = {**q, **analysis}
                analyzed.append(analyzed_q)

            return analyzed

        except Exception as e:
            logger.error(f"AIé¢˜ç›®åˆ†æå¤±è´¥: {e}")
            raise

    async def _ai_grade_questions(self, questions: List[Dict[str, Any]], grade_level: str) -> List[Dict[str, Any]]:
        """AIæ‰¹æ”¹é¢˜ç›®"""
        try:
            graded = []

            for q in questions:
                prompt = f"""
                æ‰¹æ”¹è¿™é“{grade_level}æ•°å­¦é¢˜ï¼š
                é¢˜ç›®ï¼š{q.get('question_text', '')}
                æ­£ç¡®ç­”æ¡ˆï¼š{q.get('correct_answer', '')}
                å­¦ç”Ÿç­”æ¡ˆï¼š{q.get('student_answer', '')}

                è¿”å›JSONï¼š
                {{
                    "is_correct": true/false,
                    "score": å¾—åˆ†,
                    "max_score": 10,
                    "feedback": "è¯¦ç»†åé¦ˆ",
                    "errors": ["é”™è¯¯ç‚¹"]
                }}
                """

                request_data = {
                    "model": settings.get("models.nvidia.model"),
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 800,
                    "temperature": 0.1
                }

                grading = await self.mcp_client.call_tool("nvidia_chat", request_data)

                if isinstance(grading, str):
                    try:
                        grading = json.loads(grading)
                    except:
                        grading = {"is_correct": False, "score": 0, "max_score": 10, "feedback": "æ‰¹æ”¹å¤±è´¥"}

                graded_q = {**q, **grading}
                graded.append(graded_q)

            return graded

        except Exception as e:
            logger.error(f"AIæ‰¹æ”¹å¤±è´¥: {e}")
            raise

    async def _generate_ai_feedback(self, graded_questions: List[Dict[str, Any]], grade_level: str) -> Dict[str, Any]:
        """ç”ŸæˆAIåé¦ˆ"""
        try:
            correct_count = sum(1 for q in graded_questions if q.get('is_correct', False))
            total_questions = len(graded_questions)

            prompt = f"""
            ä¸º{grade_level}å­¦ç”Ÿç”Ÿæˆç»¼åˆå­¦ä¹ åé¦ˆï¼š
            æ€»é¢˜æ•°ï¼š{total_questions}
            æ­£ç¡®æ•°ï¼š{correct_count}
            
            è¿”å›JSONï¼š
            {{
                "overall_assessment": "æ•´ä½“è¯„ä»·",
                "strengths": ["ä¼˜åŠ¿"],
                "weaknesses": ["ä¸è¶³"],
                "suggestions": ["å»ºè®®"]
            }}
            """

            request_data = {
                "model": settings.get("models.nvidia.model"),
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
                "temperature": 0.3
            }

            feedback = await self.mcp_client.call_tool("nvidia_chat", request_data)

            if isinstance(feedback, str):
                try:
                    return json.loads(feedback)
                except:
                    return {"overall_assessment": "æ‰¹æ”¹å®Œæˆ", "suggestions": ["ç»§ç»­åŠªåŠ›"]}

            return feedback

        except Exception as e:
            logger.error(f"AIåé¦ˆç”Ÿæˆå¤±è´¥: {e}")
            return {"overall_assessment": "æ‰¹æ”¹å®Œæˆ", "suggestions": ["ç»§ç»­åŠªåŠ›"]}

    async def _generate_practice_problems(self, graded_questions: List[Dict[str, Any]], grade_level: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç»ƒä¹ é¢˜"""
        try:
            # æ‰¾å‡ºé”™è¯¯çš„çŸ¥è¯†ç‚¹
            error_topics = []
            for q in graded_questions:
                if not q.get('is_correct', False):
                    topic = q.get('topic', 'åŸºç¡€è¿ç®—')
                    if topic not in error_topics:
                        error_topics.append(topic)

            if not error_topics:
                return []

            practice_problems = []
            for topic in error_topics[:2]:  # æœ€å¤š2ä¸ªçŸ¥è¯†ç‚¹
                prompt = f"""
                ä¸º{grade_level}å­¦ç”Ÿç”Ÿæˆå…³äº"{topic}"çš„ç»ƒä¹ é¢˜ï¼š
                
                è¿”å›JSONï¼š
                {{
                    "topic": "{topic}",
                    "problems": [
                        {{
                            "question": "é¢˜ç›®",
                            "answer": "ç­”æ¡ˆ",
                            "hint": "æç¤º"
                        }}
                    ]
                }}
                """

                request_data = {
                    "model": settings.get("models.nvidia.model"),
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 1000,
                    "temperature": 0.5
                }

                problems = await self.mcp_client.call_tool("nvidia_chat", request_data)

                if isinstance(problems, str):
                    try:
                        problems = json.loads(problems)
                        practice_problems.append(problems)
                    except:
                        pass

            return practice_problems

        except Exception as e:
            logger.error(f"ç»ƒä¹ é¢˜ç”Ÿæˆå¤±è´¥: {e}")
            return []

    def _compile_ai_results(self, graded_questions: List[Dict[str, Any]],
                            ai_feedback: Dict[str, Any],
                            practice_problems: List[Dict[str, Any]],
                            processing_time: float,
                            grade_level: str) -> Dict[str, Any]:
        """ç¼–è¯‘AIæ‰¹æ”¹ç»“æœ"""

        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        results = []
        for q in graded_questions:
            result = {
                "question_text": q.get("question_text", ""),
                "student_answer": q.get("student_answer", ""),
                "correct_answer": q.get("correct_answer", ""),
                "score": q.get("score", 0),
                "max_score": q.get("max_score", 10),
                "is_correct": q.get("is_correct", False),
                "initial_feedback": q.get("feedback", ""),
                "enhanced_feedback": q.get("feedback", "") + "\n" + "\n".join(q.get("errors", [])),
                "topic": q.get("topic", "åŸºç¡€æ•°å­¦"),
                "difficulty": q.get("difficulty", "ä¸­ç­‰"),
                "question_type": q.get("question_type", "è®¡ç®—é¢˜")
            }
            results.append(result)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_questions = len(results)
        correct_count = sum(1 for r in results if r["is_correct"])
        total_score = sum(r["score"] for r in results)
        max_total_score = sum(r["max_score"] for r in results)

        return {
            "success": True,
            "mode": "ai_powered",  # é‡è¦ï¼šæ ‡è¯†è¿™æ˜¯AIå¤„ç†çš„ç»“æœ
            "results": results,
            "statistics": {
                "total_questions": total_questions,
                "correct_count": correct_count,
                "accuracy_rate": (correct_count / total_questions * 100) if total_questions > 0 else 0,
                "total_score": total_score,
                "max_total_score": max_total_score,
                "score_percentage": (total_score / max_total_score * 100) if max_total_score > 0 else 0,
                "topic_breakdown": {}  # å¯ä»¥è¿›ä¸€æ­¥å®Œå–„
            },
            "ai_feedback": ai_feedback,
            "practice_problems": practice_problems,
            "processing_time": processing_time,
            "grade_level": grade_level,
            "ai_features_used": [
                "AIå›¾åƒè¯†åˆ«",
                "æ™ºèƒ½é¢˜ç›®åˆ†æ",
                "AIæ‰¹æ”¹å¼•æ“",
                "ä¸ªæ€§åŒ–åé¦ˆ",
                "é’ˆå¯¹æ€§ç»ƒä¹ é¢˜"
            ]
        }

    async def _basic_grade_homework(self, homework_id: int, image_path: str, grade_level: str) -> Dict[str, Any]:
        """åŸºç¡€æ‰¹æ”¹æ¨¡å¼ - å½“AIä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        logger.warning("ä½¿ç”¨åŸºç¡€æ‰¹æ”¹æ¨¡å¼")

        # åŸºæœ¬çš„å›¾åƒå¤„ç†
        try:
            with open(image_path, 'rb') as f:
                image_size = len(f.read())
        except:
            image_size = 0

        # æ¨¡æ‹ŸåŸºæœ¬ç»“æœ
        mock_results = {
            "success": True,
            "mode": "basic",  # æ ‡è¯†ä¸ºåŸºç¡€æ¨¡å¼
            "results": [
                {
                    "question_text": f"æ£€æµ‹åˆ°{grade_level}æ•°å­¦ä½œä¸š",
                    "student_answer": "å›¾åƒåˆ†æä¸­...",
                    "correct_answer": "éœ€è¦AIæœåŠ¡æ”¯æŒ",
                    "score": 5,
                    "max_score": 10,
                    "is_correct": False,
                    "initial_feedback": "ç³»ç»Ÿæ­£åœ¨åŸºç¡€æ¨¡å¼ä¸‹è¿è¡Œ",
                    "enhanced_feedback": "è¯·æ£€æŸ¥:\n1. NVIDIA APIå¯†é’¥é…ç½®\n2. ç½‘ç»œè¿æ¥çŠ¶æ€\n3. MCPæœåŠ¡çŠ¶æ€",
                    "topic": grade_level,
                    "difficulty": "æœªçŸ¥",
                    "question_type": "æ··åˆé¢˜å‹"
                }
            ],
            "statistics": {
                "total_questions": 1,
                "correct_count": 0,
                "accuracy_rate": 0.0,
                "total_score": 5.0,
                "max_total_score": 10.0,
                "score_percentage": 50.0
            },
            "ai_feedback": {
                "overall_assessment": "ç³»ç»Ÿè¿è¡Œåœ¨åŸºç¡€æ¨¡å¼ï¼ŒåŠŸèƒ½å—é™",
                "suggestions": ["é…ç½®AIæœåŠ¡ä»¥è·å¾—å®Œæ•´åŠŸèƒ½"]
            },
            "practice_problems": [],
            "processing_time": 0.1,
            "grade_level": grade_level,
            "ai_features_used": ["åŸºç¡€å›¾åƒæ£€æµ‹"]
        }

        return mock_results


# ===============================
# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¹Ÿåˆ›å»º RealGradingEngine åˆ«å
# ===============================

RealGradingEngine = GradingEngine  # åˆ«åï¼ŒæŒ‡å‘åŒä¸€ä¸ªç±»

# ===============================
# å¯¼å‡ºæ‰€æœ‰éœ€è¦çš„ç±»
# ===============================

__all__ = ['GradingEngine', 'RealGradingEngine']