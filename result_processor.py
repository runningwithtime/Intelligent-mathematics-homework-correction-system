# ===============================
# core/result_processor.py - ç»“æœå¤„ç†å™¨
# ===============================
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import re
import math
from collections import defaultdict

from ..config.settings import settings
from ..utils.exceptions import MathGradingException

logger = logging.getLogger(__name__)

class ResultProcessor:
    """æ‰¹æ”¹ç»“æœå¤„ç†å™¨"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def process_raw_results(self, raw_results: Dict[str, Any], grade_level: str) -> Dict[str, Any]:
        """
        å¤„ç†åŸå§‹æ‰¹æ”¹ç»“æœ

        Args:
            raw_results: AIæ¨¡å‹è¿”å›çš„åŸå§‹ç»“æœ
            grade_level: å¹´çº§æ°´å¹³

        Returns:
            å¤„ç†åçš„ç»“æ„åŒ–ç»“æœ
        """
        try:
            processed_results = {
                "success": True,
                "grade_level": grade_level,
                "processed_at": datetime.now().isoformat(),
                "questions": [],
                "statistics": {},
                "recommendations": []
            }

            # å¤„ç†é—®é¢˜åˆ—è¡¨
            raw_questions = raw_results.get("questions", [])
            if not raw_questions:
                self.logger.warning("æœªæ‰¾åˆ°é—®é¢˜æ•°æ®")
                processed_results["success"] = False
                processed_results["error"] = "æœªè¯†åˆ«åˆ°ä»»ä½•é¢˜ç›®"
                return processed_results

            # é€é¢˜å¤„ç†
            for i, raw_question in enumerate(raw_questions):
                processed_question = self._process_single_question(raw_question, i + 1, grade_level)
                processed_results["questions"].append(processed_question)

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            processed_results["statistics"] = self._calculate_statistics(processed_results["questions"])

            # ç”Ÿæˆå­¦ä¹ å»ºè®®
            processed_results["recommendations"] = self._generate_recommendations(
                processed_results["questions"],
                processed_results["statistics"],
                grade_level
            )

            self.logger.info(f"ç»“æœå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(processed_results['questions'])} é“é¢˜ç›®")
            return processed_results

        except Exception as e:
            self.logger.error(f"ç»“æœå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"ç»“æœå¤„ç†å¤±è´¥: {e}",
                "raw_results": raw_results
            }

    def _process_single_question(self, raw_question: Dict[str, Any], question_num: int, grade_level: str) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªé—®é¢˜"""
        processed_question = {
            "question_id": f"q_{question_num}",
            "question_number": question_num,
            "question_text": self._clean_text(raw_question.get("question_text", "")),
            "student_answer": self._clean_text(raw_question.get("student_answer", "")),
            "correct_answer": self._clean_text(raw_question.get("correct_answer", "")),
            "raw_score": raw_question.get("score", 0),
            "max_score": raw_question.get("max_score", 10),
            "is_correct": raw_question.get("is_correct", False),
            "raw_feedback": raw_question.get("feedback", ""),
            "topic": self._identify_topic(raw_question.get("question_text", ""), grade_level),
            "difficulty": raw_question.get("difficulty", "medium"),
            "error_type": None,
            "processed_at": datetime.now().isoformat()
        }

        # æ ‡å‡†åŒ–åˆ†æ•°
        processed_question["score"] = self._normalize_score(
            processed_question["raw_score"],
            processed_question["max_score"]
        )

        # åˆ†æé”™è¯¯ç±»å‹
        if not processed_question["is_correct"]:
            processed_question["error_type"] = self._analyze_error_type(
                processed_question["question_text"],
                processed_question["student_answer"],
                processed_question["correct_answer"]
            )

        # å¢å¼ºåé¦ˆ
        processed_question["enhanced_feedback"] = self._enhance_feedback(
            processed_question["raw_feedback"],
            processed_question["error_type"],
            processed_question["topic"]
        )

        return processed_question

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        if not text:
            return ""

        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text.strip())

        # ä¿®æ­£å¸¸è§çš„OCRé”™è¯¯
        text = text.replace('Ã—', 'Ã—').replace('Ã·', 'Ã·')
        text = text.replace('ï¼ˆ', '(').replace('ï¼‰', ')')

        return text

    def _identify_topic(self, question_text: str, grade_level: str) -> str:
        """è¯†åˆ«é¢˜ç›®æ‰€å±çŸ¥è¯†ç‚¹"""
        question_lower = question_text.lower()

        # é«˜ä¸­æ•°å­¦çŸ¥è¯†ç‚¹å…³é”®è¯æ˜ å°„
        topic_keywords = {
            "å‡½æ•°": ["å‡½æ•°", "f(x)", "å›¾åƒ", "å®šä¹‰åŸŸ", "å€¼åŸŸ", "å•è°ƒ", "å¥‡å¶"],
            "æ–¹ç¨‹": ["æ–¹ç¨‹", "è§£", "æ ¹", "x=", "æ±‚è§£"],
            "ä¸ç­‰å¼": ["ä¸ç­‰å¼", "â‰¥", "â‰¤", ">", "<", "å¤§äº", "å°äº"],
            "ä¸‰è§’å‡½æ•°": ["sin", "cos", "tan", "ä¸‰è§’", "è§’åº¦", "å¼§åº¦"],
            "æ•°åˆ—": ["æ•°åˆ—", "é€šé¡¹", "æ±‚å’Œ", "ç­‰å·®", "ç­‰æ¯”"],
            "ç«‹ä½“å‡ ä½•": ["ä½“ç§¯", "è¡¨é¢ç§¯", "æ£±é”¥", "æ£±æŸ±", "çƒ", "åœ†é”¥"],
            "å¹³é¢å‡ ä½•": ["ä¸‰è§’å½¢", "åœ†", "ç›´çº¿", "è§’", "é¢ç§¯", "å‘¨é•¿"],
            "æ¦‚ç‡ç»Ÿè®¡": ["æ¦‚ç‡", "ç»Ÿè®¡", "å‡å€¼", "æ–¹å·®", "éšæœº"],
            "å¯¼æ•°": ["å¯¼æ•°", "å¯¼å‡½æ•°", "æå€¼", "åˆ‡çº¿", "å•è°ƒæ€§"],
            "ç§¯åˆ†": ["ç§¯åˆ†", "é¢ç§¯", "å®šç§¯åˆ†", "ä¸å®šç§¯åˆ†"],
            "å‘é‡": ["å‘é‡", "åæ ‡", "å¤¹è§’", "æ•°é‡ç§¯"],
            "å¤æ•°": ["å¤æ•°", "è™šæ•°", "å®éƒ¨", "è™šéƒ¨", "i"],
            "æ’åˆ—ç»„åˆ": ["æ’åˆ—", "ç»„åˆ", "é˜¶ä¹˜", "C", "A"],
            "å¯¹æ•°": ["å¯¹æ•°", "log", "ln", "æŒ‡æ•°"]
        }

        # åŒ¹é…çŸ¥è¯†ç‚¹
        for topic, keywords in topic_keywords.items():
            for keyword in keywords:
                if keyword in question_text or keyword in question_lower:
                    return topic

        return "ç»¼åˆ"

    def _normalize_score(self, raw_score: float, max_score: float) -> float:
        """æ ‡å‡†åŒ–åˆ†æ•°"""
        if max_score <= 0:
            return 0.0

        normalized = (raw_score / max_score) * 10  # æ ‡å‡†åŒ–åˆ°10åˆ†åˆ¶
        return round(min(max(normalized, 0), 10), 1)

    def _analyze_error_type(self, question: str, student_answer: str, correct_answer: str) -> str:
        """åˆ†æé”™è¯¯ç±»å‹"""
        if not student_answer.strip():
            return "æœªä½œç­”"

        question_lower = question.lower()
        student_lower = student_answer.lower()
        correct_lower = correct_answer.lower()

        # è®¡ç®—é”™è¯¯ç±»å‹
        if "è®¡ç®—" in question_lower or any(op in question for op in ['+', '-', 'Ã—', 'Ã·']):
            # æ•°å€¼æ¯”è¾ƒ
            if self._contains_numbers(student_answer) and self._contains_numbers(correct_answer):
                student_nums = self._extract_numbers(student_answer)
                correct_nums = self._extract_numbers(correct_answer)

                if student_nums and correct_nums:
                    if abs(student_nums[0] - correct_nums[0]) < 0.01:
                        return "è¡¨è¾¾æ–¹å¼é”™è¯¯"
                    else:
                        return "è®¡ç®—é”™è¯¯"
            return "è®¡ç®—é”™è¯¯"

        elif "æ–¹ç¨‹" in question_lower:
            return "è§£æ³•é”™è¯¯"

        elif "è¯æ˜" in question_lower:
            return "é€»è¾‘é”™è¯¯"

        elif len(student_answer) < len(correct_answer) * 0.5:
            return "ç­”æ¡ˆä¸å®Œæ•´"

        else:
            return "ç†è§£é”™è¯¯"

    def _contains_numbers(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ•°å­—"""
        return bool(re.search(r'\d+(?:\.\d+)?', text))

    def _extract_numbers(self, text: str) -> List[float]:
        """ä»æ–‡æœ¬ä¸­æå–æ•°å­—"""
        numbers = re.findall(r'-?\d+(?:\.\d+)?', text)
        return [float(n) for n in numbers]

    def _enhance_feedback(self, raw_feedback: str, error_type: str, topic: str) -> str:
        """å¢å¼ºåé¦ˆå†…å®¹"""
        enhanced_parts = []

        # åŸºç¡€åé¦ˆ
        if raw_feedback:
            enhanced_parts.append(raw_feedback)

        # é”™è¯¯ç±»å‹ç‰¹å®šå»ºè®®
        error_suggestions = {
            "è®¡ç®—é”™è¯¯": "å»ºè®®ï¼šä»”ç»†æ£€æŸ¥è®¡ç®—æ­¥éª¤ï¼Œä½¿ç”¨è‰ç¨¿çº¸é€æ­¥è®¡ç®—ã€‚",
            "è§£æ³•é”™è¯¯": "å»ºè®®ï¼šå›é¡¾ç›¸å…³è§£é¢˜æ–¹æ³•ï¼Œæ³¨æ„è§£é¢˜æ­¥éª¤çš„é€»è¾‘æ€§ã€‚",
            "ç†è§£é”™è¯¯": "å»ºè®®ï¼šé‡æ–°å®¡é¢˜ï¼Œç†è§£é¢˜ç›®è¦æ±‚ï¼Œæ˜ç¡®å·²çŸ¥æ¡ä»¶ã€‚",
            "æœªä½œç­”": "å»ºè®®ï¼šå³ä½¿ä¸ç¡®å®šä¹Ÿè¦å°è¯•ä½œç­”ï¼Œå¯ä»¥å†™å‡ºæ€è·¯æˆ–éƒ¨åˆ†æ­¥éª¤ã€‚",
            "ç­”æ¡ˆä¸å®Œæ•´": "å»ºè®®ï¼šæ£€æŸ¥ç­”æ¡ˆæ˜¯å¦å®Œæ•´ï¼Œæ˜¯å¦å›ç­”äº†é¢˜ç›®çš„æ‰€æœ‰è¦æ±‚ã€‚",
            "è¡¨è¾¾æ–¹å¼é”™è¯¯": "å»ºè®®ï¼šç­”æ¡ˆæ­£ç¡®ä½†è¡¨è¾¾ä¸è§„èŒƒï¼Œæ³¨æ„æ•°å­¦è¡¨è¾¾çš„å‡†ç¡®æ€§ã€‚",
            "é€»è¾‘é”™è¯¯": "å»ºè®®ï¼šæ³¨æ„æ¨ç†çš„é€»è¾‘æ€§ï¼Œæ¯ä¸€æ­¥éƒ½è¦æœ‰å……åˆ†çš„ä¾æ®ã€‚"
        }

        if error_type in error_suggestions:
            enhanced_parts.append(error_suggestions[error_type])

        # çŸ¥è¯†ç‚¹ç‰¹å®šå»ºè®®
        topic_suggestions = {
            "å‡½æ•°": "å¤ä¹ å‡½æ•°çš„åŸºæœ¬æ¦‚å¿µå’Œæ€§è´¨ï¼Œå¤šç»ƒä¹ å‡½æ•°å›¾åƒåˆ†æã€‚",
            "æ–¹ç¨‹": "æŒæ¡å„ç±»æ–¹ç¨‹çš„æ ‡å‡†è§£æ³•ï¼Œæ³¨æ„éªŒæ ¹å’Œè§£çš„å®Œæ•´æ€§ã€‚",
            "ä¸‰è§’å‡½æ•°": "ç†Ÿè®°ä¸‰è§’å‡½æ•°çš„åŸºæœ¬å…¬å¼å’Œå›¾åƒæ€§è´¨ã€‚",
            "å¯¼æ•°": "ç†è§£å¯¼æ•°çš„å‡ ä½•æ„ä¹‰å’Œç‰©ç†æ„ä¹‰ï¼ŒæŒæ¡æ±‚å¯¼æ³•åˆ™ã€‚",
            "æ¦‚ç‡ç»Ÿè®¡": "æ˜ç¡®æ¦‚ç‡çš„å®šä¹‰å’Œè®¡ç®—æ–¹æ³•ï¼Œæ³¨æ„å®é™…é—®é¢˜çš„å»ºæ¨¡ã€‚"
        }

        if topic in topic_suggestions:
            enhanced_parts.append(f"çŸ¥è¯†ç‚¹å»ºè®®ï¼š{topic_suggestions[topic]}")

        return " ".join(enhanced_parts)

    def _calculate_statistics(self, questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if not questions:
            return {}

        total_questions = len(questions)
        correct_count = sum(1 for q in questions if q["is_correct"])
        total_score = sum(q["score"] for q in questions)
        max_total_score = sum(q["max_score"] for q in questions)

        # æŒ‰çŸ¥è¯†ç‚¹ç»Ÿè®¡
        topic_stats = defaultdict(lambda: {"total": 0, "correct": 0, "total_score": 0, "max_score": 0})

        for question in questions:
            topic = question["topic"]
            topic_stats[topic]["total"] += 1
            topic_stats[topic]["max_score"] += question["max_score"]
            topic_stats[topic]["total_score"] += question["score"]
            if question["is_correct"]:
                topic_stats[topic]["correct"] += 1

        # é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_types = defaultdict(int)
        for question in questions:
            if not question["is_correct"] and question["error_type"]:
                error_types[question["error_type"]] += 1

        # éš¾åº¦åˆ†å¸ƒ
        difficulty_stats = defaultdict(lambda: {"total": 0, "correct": 0})
        for question in questions:
            difficulty = question["difficulty"]
            difficulty_stats[difficulty]["total"] += 1
            if question["is_correct"]:
                difficulty_stats[difficulty]["correct"] += 1

        return {
            "total_questions": total_questions,
            "correct_questions": correct_count,
            "wrong_questions": total_questions - correct_count,
            "accuracy_rate": round((correct_count / total_questions * 100), 2) if total_questions > 0 else 0,
            "total_score": round(total_score, 2),
            "max_total_score": round(max_total_score, 2),
            "score_rate": round((total_score / max_total_score * 100), 2) if max_total_score > 0 else 0,
            "topic_breakdown": dict(topic_stats),
            "error_type_distribution": dict(error_types),
            "difficulty_distribution": dict(difficulty_stats)
        }

    def _generate_recommendations(self, questions: List[Dict[str, Any]], statistics: Dict[str, Any], grade_level: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå­¦ä¹ å»ºè®®"""
        recommendations = []

        # åŸºäºæ­£ç¡®ç‡çš„å»ºè®®
        accuracy_rate = statistics.get("accuracy_rate", 0)

        if accuracy_rate >= 90:
            recommendations.append({
                "type": "praise",
                "priority": "low",
                "title": "è¡¨ç°ä¼˜ç§€",
                "content": "ä½ çš„ç­”é¢˜å‡†ç¡®ç‡å¾ˆé«˜ï¼ŒåŸºç¡€æŒæ¡å¾—å¾ˆå¥½ï¼å»ºè®®æŒ‘æˆ˜ä¸€äº›æ›´æœ‰éš¾åº¦çš„é¢˜ç›®ã€‚",
                "actions": ["ç»ƒä¹ ç»¼åˆé¢˜", "å°è¯•ç«èµ›é¢˜ç›®", "å¸®åŠ©åŒå­¦ç­”ç–‘"]
            })
        elif accuracy_rate >= 70:
            recommendations.append({
                "type": "improvement",
                "priority": "medium",
                "title": "ç»§ç»­åŠªåŠ›",
                "content": "åŸºç¡€è¿˜ä¸é”™ï¼Œä½†è¿˜æœ‰æå‡ç©ºé—´ã€‚é‡ç‚¹å…³æ³¨é”™è¯¯é¢˜ç›®çš„çŸ¥è¯†ç‚¹ã€‚",
                "actions": ["å¤ä¹ é”™é¢˜", "å¼ºåŒ–ç»ƒä¹ ", "å‘è€å¸ˆè¯·æ•™"]
            })
        else:
            recommendations.append({
                "type": "attention",
                "priority": "high",
                "title": "éœ€è¦åŠ å¼º",
                "content": "åŸºç¡€çŸ¥è¯†æŒæ¡ä¸å¤Ÿæ‰å®ï¼Œå»ºè®®ç³»ç»Ÿå¤ä¹ ç›¸å…³ç« èŠ‚ã€‚",
                "actions": ["å›é¡¾æ•™æ", "åŸºç¡€ç»ƒä¹ ", "å¯»æ±‚å¸®åŠ©"]
            })

        # åŸºäºçŸ¥è¯†ç‚¹çš„å»ºè®®
        topic_breakdown = statistics.get("topic_breakdown", {})
        weak_topics = []

        for topic, stats in topic_breakdown.items():
            if stats["total"] > 0:
                topic_accuracy = (stats["correct"] / stats["total"]) * 100
                if topic_accuracy < 60:  # æ­£ç¡®ç‡ä½äº60%
                    weak_topics.append((topic, topic_accuracy))

        if weak_topics:
            weak_topics.sort(key=lambda x: x[1])  # æŒ‰æ­£ç¡®ç‡æ’åº
            top_weak_topic = weak_topics[0][0]

            recommendations.append({
                "type": "focus",
                "priority": "high",
                "title": f"é‡ç‚¹å…³æ³¨ï¼š{top_weak_topic}",
                "content": f"åœ¨{top_weak_topic}æ–¹é¢é”™è¯¯è¾ƒå¤šï¼Œå»ºè®®é‡ç‚¹å¤ä¹ è¿™éƒ¨åˆ†å†…å®¹ã€‚",
                "actions": [f"å¤ä¹ {top_weak_topic}ç›¸å…³æ¦‚å¿µ", f"ç»ƒä¹ {top_weak_topic}åŸºç¡€é¢˜", "æ€»ç»“å¸¸è§é¢˜å‹"]
            })

        # åŸºäºé”™è¯¯ç±»å‹çš„å»ºè®®
        error_distribution = statistics.get("error_type_distribution", {})
        if error_distribution:
            most_common_error = max(error_distribution.items(), key=lambda x: x[1])
            error_type, count = most_common_error

            error_advice = {
                "è®¡ç®—é”™è¯¯": {
                    "title": "æé«˜è®¡ç®—å‡†ç¡®æ€§",
                    "content": "è®¡ç®—é”™è¯¯æ¯”è¾ƒå¤šï¼Œå»ºè®®åŠ å¼ºåŸºæœ¬è¿ç®—ç»ƒä¹ ã€‚",
                    "actions": ["æ¯æ—¥è®¡ç®—ç»ƒä¹ ", "ä½¿ç”¨è‰ç¨¿çº¸", "éªŒç®—ç»“æœ"]
                },
                "ç†è§£é”™è¯¯": {
                    "title": "åŠ å¼ºé¢˜æ„ç†è§£",
                    "content": "å®¡é¢˜ä¸å¤Ÿä»”ç»†ï¼Œå»ºè®®å¤šèŠ±æ—¶é—´ç†è§£é¢˜ç›®è¦æ±‚ã€‚",
                    "actions": ["ä»”ç»†å®¡é¢˜", "ç”»å›¾è¾…åŠ©ç†è§£", "æ ‡è®°å…³é”®è¯"]
                },
                "è§£æ³•é”™è¯¯": {
                    "title": "å·©å›ºè§£é¢˜æ–¹æ³•",
                    "content": "è§£é¢˜æ–¹æ³•æœ‰è¯¯ï¼Œå»ºè®®å›é¡¾æ ‡å‡†è§£æ³•ã€‚",
                    "actions": ["å¤ä¹ è§£é¢˜æ¨¡æ¿", "æ€»ç»“æ–¹æ³•è§„å¾‹", "å¤šç»ƒä¹ ç±»ä¼¼é¢˜å‹"]
                }
            }

            if error_type in error_advice:
                advice = error_advice[error_type]
                recommendations.append({
                    "type": "method",
                    "priority": "medium",
                    "title": advice["title"],
                    "content": advice["content"],
                    "actions": advice["actions"]
                })

        return recommendations

class ScoreCalculator:
    """åˆ†æ•°è®¡ç®—å™¨"""

    @staticmethod
    def calculate_weighted_score(questions: List[Dict[str, Any]], weights: Dict[str, float] = None) -> float:
        """è®¡ç®—åŠ æƒåˆ†æ•°"""
        if not questions:
            return 0.0

        if not weights:
            weights = {"easy": 1.0, "medium": 1.2, "hard": 1.5}

        total_weighted_score = 0
        total_weight = 0

        for question in questions:
            difficulty = question.get("difficulty", "medium")
            weight = weights.get(difficulty, 1.0)
            score = question.get("score", 0)

            total_weighted_score += score * weight
            total_weight += weight

        return round(total_weighted_score / total_weight, 2) if total_weight > 0 else 0.0

    @staticmethod
    def calculate_improvement_score(current_questions: List[Dict[str, Any]],
                                    previous_questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—è¿›æ­¥åˆ†æ•°"""
        if not current_questions or not previous_questions:
            return {"improvement": 0, "trend": "unknown"}

        current_accuracy = sum(1 for q in current_questions if q.get("is_correct", False)) / len(current_questions)
        previous_accuracy = sum(1 for q in previous_questions if q.get("is_correct", False)) / len(previous_questions)

        improvement = (current_accuracy - previous_accuracy) * 100

        if improvement > 5:
            trend = "improving"
        elif improvement < -5:
            trend = "declining"
        else:
            trend = "stable"

        return {
            "improvement": round(improvement, 2),
            "trend": trend,
            "current_accuracy": round(current_accuracy * 100, 2),
            "previous_accuracy": round(previous_accuracy * 100, 2)
        }

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, result_processor: ResultProcessor):
        self.result_processor = result_processor
        self.logger = logging.getLogger(__name__)

    def generate_detailed_report(self, processed_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        try:
            questions = processed_results.get("questions", [])
            statistics = processed_results.get("statistics", {})
            recommendations = processed_results.get("recommendations", [])

            report_lines = []
            report_lines.append("=" * 60)
            report_lines.append("æ•°å­¦ä½œä¸šæ‰¹æ”¹è¯¦ç»†æŠ¥å‘Š")
            report_lines.append("=" * 60)
            report_lines.append("")

            # åŸºæœ¬ä¿¡æ¯
            report_lines.append("ğŸ“Š åŸºæœ¬ç»Ÿè®¡")
            report_lines.append("-" * 30)
            report_lines.append(f"æ€»é¢˜æ•°: {statistics.get('total_questions', 0)}")
            report_lines.append(f"æ­£ç¡®é¢˜æ•°: {statistics.get('correct_questions', 0)}")
            report_lines.append(f"é”™è¯¯é¢˜æ•°: {statistics.get('wrong_questions', 0)}")
            report_lines.append(f"æ­£ç¡®ç‡: {statistics.get('accuracy_rate', 0):.1f}%")
            report_lines.append(f"æ€»åˆ†: {statistics.get('total_score', 0):.1f}/{statistics.get('max_total_score', 0):.1f}")
            report_lines.append(f"å¾—åˆ†ç‡: {statistics.get('score_rate', 0):.1f}%")
            report_lines.append("")

            # çŸ¥è¯†ç‚¹åˆ†æ
            topic_breakdown = statistics.get("topic_breakdown", {})
            if topic_breakdown:
                report_lines.append("ğŸ“š çŸ¥è¯†ç‚¹åˆ†æ")
                report_lines.append("-" * 30)
                for topic, stats in topic_breakdown.items():
                    accuracy = (stats["correct"] / stats["total"] * 100) if stats["total"] > 0 else 0
                    report_lines.append(f"{topic}: {stats['correct']}/{stats['total']} ({accuracy:.1f}%)")
                report_lines.append("")

            # é”™è¯¯åˆ†æ
            error_distribution = statistics.get("error_type_distribution", {})
            if error_distribution:
                report_lines.append("âŒ é”™è¯¯ç±»å‹åˆ†æ")
                report_lines.append("-" * 30)
                for error_type, count in error_distribution.items():
                    report_lines.append(f"{error_type}: {count}æ¬¡")
                report_lines.append("")

            # è¯¦ç»†é¢˜ç›®åˆ†æ
            report_lines.append("ğŸ“ è¯¦ç»†é¢˜ç›®åˆ†æ")
            report_lines.append("-" * 30)
            for i, question in enumerate(questions, 1):
                status = "âœ“" if question["is_correct"] else "âœ—"
                report_lines.append(f"{i}. [{status}] {question['question_text'][:50]}...")
                report_lines.append(f"   å­¦ç”Ÿç­”æ¡ˆ: {question['student_answer']}")
                report_lines.append(f"   æ­£ç¡®ç­”æ¡ˆ: {question['correct_answer']}")
                report_lines.append(f"   å¾—åˆ†: {question['score']:.1f}/{question['max_score']:.1f}")
                if question.get("enhanced_feedback"):
                    report_lines.append(f"   åé¦ˆ: {question['enhanced_feedback']}")
                report_lines.append("")

            # å»ºè®®
            if recommendations:
                report_lines.append("ğŸ’¡ å­¦ä¹ å»ºè®®")
                report_lines.append("-" * 30)
                for i, rec in enumerate(recommendations, 1):
                    report_lines.append(f"{i}. {rec['title']}")
                    report_lines.append(f"   {rec['content']}")
                    if rec.get("actions"):
                        report_lines.append(f"   å»ºè®®è¡ŒåŠ¨: {', '.join(rec['actions'])}")
                    report_lines.append("")

            report_lines.append("=" * 60)
            report_lines.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report_lines.append("=" * 60)

            return "\n".join(report_lines)

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šå¤±è´¥: {e}")
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"